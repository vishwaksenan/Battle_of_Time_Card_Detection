{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "Creating a video by predicting ID of cards in the given video file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing the task 3 model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task3_model = tf.keras.models.load_model('output_files/iva_task3_transfer.h5')\n",
    "def input_image_pipeline(img, height=224, width=224):\n",
    "    '''\n",
    "    Pipeline function to convert the localized card for prediction\n",
    "    '''\n",
    "    try:\n",
    "        res = cv2.resize(img, (width, height), interpolation = cv2.INTER_AREA) # resize it in (224 x 244)\n",
    "        return res, True # True when resize was successfull\n",
    "    except:\n",
    "        return [], False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to get the card if it is tilted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tilted_img_crop(frame, rect):\n",
    "    '''\n",
    "    Returns the cropped image and the bounding box points\n",
    "    frame -> image in which there is a bounding box\n",
    "    rect -> rectangle points with angle\n",
    "    '''\n",
    "    angle = rect[2] # Get the angle of the rectangle\n",
    "    rows,cols = frame.shape[0], frame.shape[1] # Get the rows and col of frame\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),angle,1) # Create a rotational matrix using cv2 API\n",
    "    frame_rot = cv2.warpAffine(frame,M,(cols,rows)) # Rotate the frame using M and shape of the frame\n",
    "    box = cv2.boxPoints(rect) # Get the bounding boxes\n",
    "    pts = np.int0(cv2.transform(np.array([box]), M))[0] # Get 4 rectangluar points\n",
    "    pts[pts < 0] = 0 \n",
    "    crop = frame_rot[pts[1][1]:pts[0][1], pts[1][0]:pts[2][0]]\n",
    "    return crop, pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do the prediction on video-001.mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL FRAMES - 217\n",
      "----------- Processing the frames -----------\n",
      "10 frames processed\n",
      "20 frames processed\n",
      "30 frames processed\n",
      "40 frames processed\n",
      "50 frames processed\n",
      "60 frames processed\n",
      "70 frames processed\n",
      "80 frames processed\n",
      "90 frames processed\n",
      "100 frames processed\n",
      "110 frames processed\n",
      "120 frames processed\n",
      "130 frames processed\n",
      "140 frames processed\n",
      "150 frames processed\n",
      "160 frames processed\n",
      "170 frames processed\n",
      "180 frames processed\n",
      "190 frames processed\n",
      "200 frames processed\n",
      "210 frames processed\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'iva_files/DATA/'\n",
    "results_dir = 'iva_files/results/'\n",
    "first_video = data_dir + 'video-001.MOV'\n",
    "cap = cv2.VideoCapture(first_video) # Read the video frames\n",
    "total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # Just for stat purpose\n",
    "print('TOTAL FRAMES -',total)\n",
    "res_video = [] # Saving each frame's prediction\n",
    "print(\"----------- Processing the frames -----------\")\n",
    "count = 0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if(ret):\n",
    "        count += 1\n",
    "        # Applying task used in get_test_cards.ipynb\n",
    "        low_green = np.array([25, 52, 72])\n",
    "        high_green = np.array([102, 255, 255])\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv, low_green, high_green)\n",
    "        mask = 255-mask\n",
    "        res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for i in range(len(contours)):\n",
    "            area = cv2.contourArea(contours[i])\n",
    "            if(area > 30000):\n",
    "                rect = cv2.minAreaRect(contours[i])\n",
    "                card, pts = tilted_img_crop(frame, rect)\n",
    "                box = cv2.boxPoints(rect)\n",
    "                cbox = np.int0(box)\n",
    "                card, isvalid = input_image_pipeline(card) # Preproccessing the card\n",
    "                if(isvalid == False):\n",
    "                    continue\n",
    "                # Predicting the ID of the preprocessed card\n",
    "                id = np.argmax(task3_model.predict(tf.expand_dims(card, axis=0))) \n",
    "                pos = (cbox[2][0], cbox[2][1])\n",
    "                # Writing the prediction above the localized card.\n",
    "                cv2.putText(frame, str(id), pos, cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 127, 255), 4, cv2.LINE_AA) \n",
    "                cv2.drawContours(frame,[cbox],0,(255,0,255),4)\n",
    "        res_video.append(frame)\n",
    "        if(count%10==0):\n",
    "            print(count, 'frames processed')\n",
    "    else:\n",
    "        break\n",
    "print('---------------------------------------------')\n",
    "cap.release()\n",
    "res_video = np.array(res_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the result for video-001 in task4_result4.avi video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing the frames in task4_result1.avi video file - Done\n"
     ]
    }
   ],
   "source": [
    "first_video_result = results_dir + 'task4_result1.avi'\n",
    "size = (res_video[1].shape[1], res_video[1].shape[0])\n",
    "print('Writing the frames in task4_result1.avi video file -', end=\" \")\n",
    "# Building the object to write it as a video file\n",
    "out = cv2.VideoWriter(first_video_result,cv2.VideoWriter_fourcc(*'DIVX'), 15, size) \n",
    "for i in range(len(res_video)):\n",
    "    out.write(res_video[i])\n",
    "out.release()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL FRAMES - 524\n",
      "----------- Processing the frames -----------\n",
      "10 frames processed\n",
      "20 frames processed\n",
      "30 frames processed\n",
      "40 frames processed\n",
      "50 frames processed\n",
      "60 frames processed\n",
      "70 frames processed\n",
      "80 frames processed\n",
      "90 frames processed\n",
      "100 frames processed\n",
      "110 frames processed\n",
      "120 frames processed\n",
      "130 frames processed\n",
      "140 frames processed\n",
      "150 frames processed\n",
      "160 frames processed\n",
      "170 frames processed\n",
      "180 frames processed\n",
      "190 frames processed\n",
      "200 frames processed\n",
      "210 frames processed\n",
      "220 frames processed\n",
      "230 frames processed\n",
      "240 frames processed\n",
      "250 frames processed\n",
      "260 frames processed\n",
      "270 frames processed\n",
      "280 frames processed\n",
      "290 frames processed\n",
      "300 frames processed\n",
      "310 frames processed\n",
      "320 frames processed\n",
      "330 frames processed\n",
      "340 frames processed\n",
      "350 frames processed\n",
      "360 frames processed\n",
      "370 frames processed\n",
      "380 frames processed\n",
      "390 frames processed\n",
      "400 frames processed\n",
      "410 frames processed\n",
      "420 frames processed\n",
      "430 frames processed\n",
      "440 frames processed\n",
      "450 frames processed\n",
      "460 frames processed\n",
      "470 frames processed\n",
      "480 frames processed\n",
      "490 frames processed\n",
      "500 frames processed\n",
      "510 frames processed\n",
      "520 frames processed\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Same explanation on video-001 video prediction\n",
    "second_video = data_dir + 'video-002.MOV'\n",
    "cap = cv2.VideoCapture(second_video)\n",
    "total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print('TOTAL FRAMES -',total)\n",
    "res_video = []\n",
    "print(\"----------- Processing the frames -----------\")\n",
    "count = 0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if(ret):\n",
    "        count += 1\n",
    "        low_green = np.array([25, 52, 72])\n",
    "        high_green = np.array([102, 255, 255])\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv, low_green, high_green)\n",
    "        mask = 255-mask\n",
    "        res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for i in range(len(contours)):\n",
    "            area = cv2.contourArea(contours[i])\n",
    "            if(area > 30000):\n",
    "                rect = cv2.minAreaRect(contours[i])\n",
    "                card, pts = tilted_img_crop(frame, rect)\n",
    "                box = cv2.boxPoints(rect)\n",
    "                cbox = np.int0(box)\n",
    "                card, isvalid = input_image_pipeline(card)\n",
    "                if(isvalid == False):\n",
    "                    continue\n",
    "                id = np.argmax(task3_model.predict(tf.expand_dims(card, axis=0)))\n",
    "                pos = (cbox[2][0], cbox[2][1])\n",
    "                cv2.putText(frame, str(id), pos, cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 127, 255), 4, cv2.LINE_AA)\n",
    "                cv2.drawContours(frame,[cbox],0,(255,0,255),4)\n",
    "        res_video.append(frame)\n",
    "        if(count%10==0):\n",
    "            print(count, 'frames processed')\n",
    "    else:\n",
    "        break\n",
    "print('---------------------------------------------')\n",
    "cap.release()\n",
    "res_video = np.array(res_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing the frames in task4_result2.avi video file - Done\n"
     ]
    }
   ],
   "source": [
    "second_video_result = results_dir + 'task4_result2.avi'\n",
    "size = (res_video[1].shape[1], res_video[1].shape[0])\n",
    "print('Writing the frames in task4_result2.avi video file -', end=\" \")\n",
    "out = cv2.VideoWriter(second_video_result,cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    "for i in range(len(res_video)):\n",
    "    out.write(res_video[i])\n",
    "out.release()\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
